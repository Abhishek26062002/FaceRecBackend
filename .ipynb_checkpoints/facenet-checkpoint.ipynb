{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import io\n",
    "from keras.layers import GlobalAveragePooling2D,Dense,Dropout,Input,BatchNormalization,Lambda, Flatten, Dropout,MaxPooling2D \n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import argparse\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import RandomRotation,RandomFlip\n",
    "import keras\n",
    "import  keras.callbacks as callback\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputPath = 'Images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainDataset(datapath, state):\n",
    "    files = os.listdir(datapath)\n",
    "    file_ = []\n",
    "    label = []\n",
    "    if state:\n",
    "        Files = [file for file in files]\n",
    "    else:\n",
    "        Files = [file for file in files]\n",
    "    for file in Files:\n",
    "        file_.append(file)\n",
    "        label.append(file)  # Each file is its own class\n",
    "    return np.array([file_, label]).T, np.unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataSet,TrainClasses=TrainDataset(InputPath,True)\n",
    "TestDataSet,TestClasses=TrainDataset(InputPath,False)\n",
    "np.random.shuffle(TrainDataSet)\n",
    "TrainImagesName,TrainImagesLabel=TrainDataSet[:,0],TrainDataSet[:,1]\n",
    "TrainClassesCount=len(TrainClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainClassesCount=4\n",
      "TrainImagesName=4\n"
     ]
    }
   ],
   "source": [
    "print(f\"TrainClassesCount={TrainClassesCount}\")\n",
    "print(f\"TrainImagesName={len(TrainImagesName)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestClassesCount= 4\n",
      "TestImagesName=4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TestImagesName,TestImagesLabel=TestDataSet[:,0],TestDataSet[:,1]\n",
    "TestClassesCount=len(TestClasses)\n",
    "print(f\"TestClassesCount= {TestClassesCount}\")\n",
    "print(f\"TestImagesName={len(TestImagesName)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=np.zeros(shape=(224,224,3))\n",
    "mask[:,:,0]=200\n",
    "mask[:,:,1]=100\n",
    "mask[:,:,2]=200\n",
    "mask=tf.cast(mask/255,tf.float32)\n",
    "FliPer=RandomFlip(mode=\"horizontal\")\n",
    "Rotater=RandomRotation([-0.125,0.125])\n",
    "def PreProcessInput(Image,num):\n",
    "    if num ==0:\n",
    "        Image=FliPer(Image)\n",
    "    elif num==1:\n",
    "        Image= 0.75*Image+0.25*mask\n",
    "    if num<=2:\n",
    "         return Rotater(Image)\n",
    "    else:\n",
    "         return Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_image(Anchor,Positive,Nagative,State):\n",
    "\n",
    "    Anchor=tf.io.read_file(Anchor)\n",
    "    Anchor=tf.image.decode_jpeg(Anchor)\n",
    "    Anchor = tf.cast(Anchor, tf.float32)\n",
    "    Anchor = tf.image.resize(Anchor, [224,224], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    ranA=tf.random.uniform(shape=[1],minval=0,maxval=4,dtype=tf.int32)\n",
    "\n",
    "    Positive=tf.io.read_file(Positive)\n",
    "    Positive=tf.image.decode_jpeg(Positive)\n",
    "    Positive = tf.cast(Positive, tf.float32)\n",
    "    Positive = tf.image.resize(Positive, [224,224], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    ranP=tf.random.uniform(shape=[1],minval=0,maxval=4,dtype=tf.int32)\n",
    "\n",
    "    Negative=tf.io.read_file(Nagative)\n",
    "    Negative=tf.image.decode_jpeg(Negative)\n",
    "    Negative = tf.cast(Negative, tf.float32)\n",
    "    Negative = tf.image.resize(Negative, [224,224], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    ranN=tf.random.uniform(shape=[1],minval=0,maxval=4,dtype=tf.int32)\n",
    "    if State:\n",
    "        Anchor=PreProcessInput(Anchor/255,ranA)\n",
    "        Positive=PreProcessInput(Positive/255,ranP)\n",
    "        Negative=PreProcessInput(Negative/255,ranN)\n",
    "    else:\n",
    "        Anchor=Anchor/255\n",
    "        Positive=Positive/255\n",
    "        Negative=Negative/255\n",
    "\n",
    "    return Anchor,Positive,Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DatasetTripletsGenerator(State):\n",
    "    if State:\n",
    "        np.random.shuffle(TrainDataSet)\n",
    "        ImagesName=TrainImagesName\n",
    "        ImagesLabel=TrainImagesLabel\n",
    "        ClassesCount=TrainClassesCount\n",
    "        Classes=TrainClasses\n",
    "    else:\n",
    "        ImagesName=TestImagesName\n",
    "        ImagesLabel=TestImagesLabel\n",
    "        ClassesCount=TestClassesCount\n",
    "        Classes=TestClasses\n",
    "        \n",
    "    TripletList=[]\n",
    "    for i in range(ClassesCount):\n",
    "        class_=Classes[i]\n",
    "        files=list(ImagesName[ImagesLabel==class_])[:15]\n",
    "        files_num=len(files)\n",
    "        for index in range(files_num-1):\n",
    "            for j in range(index+1,files_num):\n",
    "                ancore=InputPath+class_+files[index]\n",
    "                positive=InputPath+class_+files[j]\n",
    "                neg_folder=class_\n",
    "                while neg_folder== class_:\n",
    "                    neg_folder=np.random.choice(Classes)\n",
    "                negative=InputPath+neg_folder+np.random.choice(list(ImagesName[ImagesLabel==neg_folder]))\n",
    "                yield ancore,positive,negative,State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData=tf.data.Dataset.from_generator(DatasetTripletsGenerator,args=[True],output_types=(tf.string,tf.string,tf.string,tf.bool),output_shapes=((),(),(),()),name=\"DataLoaderPipeline\")\n",
    "TrainData=TrainData.map(load_image)\n",
    "TrainData=TrainData.batch(1)\n",
    "TrainData=TrainData.prefetch(buffer_size=1)\n",
    "# data=data.cache()\n",
    "TestData=tf.data.Dataset.from_generator(DatasetTripletsGenerator,args=[False],output_types=(tf.string,tf.string,tf.string,tf.bool),output_shapes=((),(),(),()),name=\"DataLoaderPipeline\")\n",
    "TestData=TestData.map(load_image).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def call(self,anchor,positive,negative):\n",
    "        dis_ap=tf.reduce_sum(tf.square(anchor - positive), 1)  ## distance between anchor and positive\n",
    "        dis_an=tf.reduce_sum(tf.square(anchor - negative), 1)   ## distance between anchor and negative\n",
    "        return  dis_ap , dis_an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetEncoder():\n",
    "    \n",
    "    model = tf.keras.applications.MobileNetV3Small(\n",
    "    alpha=1.0,\n",
    "    minimalistic=False,\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    dropout_rate=0.2,\n",
    "    classifier_activation='softmax',\n",
    "    include_preprocessing=True\n",
    "                                                )   \n",
    "   \n",
    "    encode_model =Sequential([\n",
    "        model,\n",
    "        Dropout(0.2),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n",
    "    ], name=\"Encoder\")\n",
    "    return encode_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SiameseNetwork(inputshape=(224,224,3)):\n",
    "    An_input=Input(shape=inputshape)\n",
    "\n",
    "    Po_input=Input(shape=inputshape)\n",
    "\n",
    "    Ne_input=Input(shape=inputshape)\n",
    "\n",
    "    encoder=GetEncoder()\n",
    "\n",
    "    An_embeding=encoder(An_input)\n",
    "    Po_embeding=encoder(Po_input)\n",
    "    Ne_embeding=encoder(Ne_input)\n",
    "\n",
    "\n",
    "    distanc=DistanceLayer()(An_embeding,Po_embeding,Ne_embeding) #return distance between (A and B) and (A and N)\n",
    "\n",
    "    return Model(inputs=[An_input,Po_input,Ne_input],outputs=distanc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhishek\\anaconda3\\Lib\\site-packages\\keras\\src\\applications\\mobilenet_v3.py:452: UserWarning: `input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  return MobileNetV3(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n",
      "\u001b[1m4334752/4334752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_33      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_34      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_35      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Encoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,367,920</span> │ input_layer_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │ input_layer_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ input_layer_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ distance_layer_4    │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DistanceLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]   │            │ Encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ Encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_33      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_34      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_35      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Encoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,367,920\u001b[0m │ input_layer_33[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │ input_layer_34[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ input_layer_35[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ distance_layer_4    │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │          \u001b[38;5;34m0\u001b[0m │ Encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mDistanceLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)]   │            │ Encoder[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ Encoder[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,367,920</span> (5.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,367,920\u001b[0m (5.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,354,784</span> (5.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,354,784\u001b[0m (5.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,136</span> (51.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m13,136\u001b[0m (51.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "siames_net=SiameseNetwork()\n",
    "siames_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiamesModel(Model):\n",
    "    def __init__(self,siames_net,DesiredDistance):\n",
    "        super(SiamesModel, self).__init__()\n",
    "\n",
    "        self.Model=siames_net\n",
    "        self.DesiredDistance=DesiredDistance\n",
    "        self.LossTracker=tf.keras.metrics.Mean(name=\"Loss\")\n",
    "\n",
    "        self.VALTracker=tf.keras.metrics.Mean(name=\"VAL\")\n",
    "\n",
    "        self.PmeanTracker=tf.keras.metrics.Mean(name=\"P_mean\")\n",
    "\n",
    "        self.PmaxTracker=tf.keras.metrics.Mean(name=\"P_max\")\n",
    "\n",
    "        self.PstdTracker=tf.keras.metrics.Mean(name=\"P_std\")\n",
    "\n",
    "        self.FARTracker=tf.keras.metrics.Mean(name=\"FAR\")\n",
    "\n",
    "        self.N_meanTracker=tf.keras.metrics.Mean(name=\"N_mean\")\n",
    "\n",
    "        self.NstdTracker=tf.keras.metrics.Mean(name=\"N_std\")\n",
    "        self.NminTracker=tf.keras.metrics.Mean(name=\"N_min\")\n",
    "\n",
    "    def call(self,data):\n",
    "        return self.Model(data)\n",
    "\n",
    "    def train_step(self,data):\n",
    "        with tf.GradientTape() as Tape:\n",
    "            AP_distanc,AN_distance=self.Model(data)\n",
    "            loss=self.TripLoss(AP_distanc,AN_distance)\n",
    "            gradients=Tape.gradient(loss,self.Model.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(gradients, self.Model.trainable_weights))\n",
    "        self.DistanceEval(AP_distanc,AN_distance)\n",
    "        self.LossTracker.update_state(loss)\n",
    "        return {\"VAL\":self.VALTracker.result(),\n",
    "                \"P_mean\":self.PmeanTracker.result(),\n",
    "                \"P_max\":self.PmaxTracker.result(),\n",
    "                \"P_std\":self.PstdTracker.result(),\n",
    "                \"FAR\":self.FARTracker.result(),\n",
    "                \"N_mean\":self.N_meanTracker.result(),\n",
    "                \"N_min\":self.NminTracker.result(),\n",
    "                \"N_std\":self.NstdTracker.result(),\n",
    "                \"Loss\":self.LossTracker.result()}\n",
    "\n",
    "\n",
    "    def test_step(self, data):\n",
    "        AP_distanc,AN_distance=self.Model(data)\n",
    "        loss=self.TripLoss(AP_distanc,AN_distance)\n",
    "        self.LossTracker.update_state(loss)\n",
    "        self.DistanceEval(AP_distanc,AN_distance)\n",
    "        return {\"VAL\":self.VALTracker.result(),\n",
    "                \"P_mean\":self.PmeanTracker.result(),\n",
    "                \"P_max\":self.PmaxTracker.result(),\n",
    "                \"P_std\":self.PstdTracker.result(),\n",
    "                \"FAR\":self.FARTracker.result(),\n",
    "                \"N_mean\":self.N_meanTracker.result(),\n",
    "                \"N_min\":self.NminTracker.result(),\n",
    "                \"N_std\":self.NstdTracker.result(),\n",
    "                \"Loss\":self.LossTracker.result()}\n",
    "\n",
    "\n",
    "\n",
    "    def TripLoss(self,ap_distance,an_distance):\n",
    "        return 3*tf.reduce_mean(tf.maximum(ap_distance-0.2*self.DesiredDistance,0.0)+tf.maximum(self.DesiredDistance-an_distance, 0.0))\n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.LossTracker,self.VALTracker,self.PmaxTracker,self.PmeanTracker,self.PstdTracker,self.FARTracker,self.N_meanTracker,self.NminTracker,self.NstdTracker]\n",
    "\n",
    "    def DistanceEval(self,P_distance,N_distance):\n",
    "        \n",
    "        P_pred,N_pred=self.TDEvaluation(P_distance,N_distance)\n",
    "        PCDCount=tf.cast(tf.reduce_sum(P_pred),dtype=tf.int32)\n",
    "        \n",
    "        VAL=PCDCount/tf.size(P_pred)\n",
    "        self.VALTracker.update_state(VAL)\n",
    "\n",
    "        NCDcount=tf.cast(tf.reduce_sum(N_pred),dtype=tf.int32)\n",
    "        FAR=1-(NCDcount/tf.size(N_pred))\n",
    "        self.FARTracker.update_state(FAR)\n",
    "        P_mean=tf.reduce_mean(P_distance)\n",
    "        self.PmeanTracker.update_state(P_mean)\n",
    "        N_mean=tf.reduce_mean(N_distance)\n",
    "        self.N_meanTracker.update_state(N_mean)\n",
    "        P_std=tf.math.reduce_std(P_distance)\n",
    "        self.PstdTracker.update_state(P_std)\n",
    "        N_std=tf.math.reduce_std(N_distance)\n",
    "        self.NstdTracker.update_state(N_std)\n",
    "        P_max=tf.reduce_max(P_distance)\n",
    "        self.PmaxTracker.update_state(P_max)\n",
    "        N_min=tf.reduce_min(N_distance)\n",
    "        self.NminTracker.update_state(N_min)\n",
    "\n",
    "    def TDEvaluation(self,P_distance,N_distance):\n",
    "        return tf.cast(P_distance<=self.DesiredDistance,dtype=tf.int8),tf.cast(N_distance>self.DesiredDistance,dtype=tf.int8)\n",
    "DesiredDistance=1\n",
    "Optimizer= Adam(learning_rate=1e-3)\n",
    "Siamesmodel=SiamesModel(siames_net,DesiredDistance)\n",
    "Siamesmodel.compile(optimizer=Optimizer,weighted_metrics=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(epoch,lr):\n",
    "    if epoch<5:\n",
    "        return 5e-3\n",
    "    elif epoch<8:\n",
    "        return 3e-3\n",
    "    elif epoch<35:\n",
    "        return 1e-3\n",
    "    elif epoch <37:\n",
    "        return 5e-4\n",
    "    else :\n",
    "        return 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRcallback=callback.LearningRateScheduler(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhishek\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history\u001b[38;5;241m=\u001b[39mSiamesmodel\u001b[38;5;241m.\u001b[39mfit(TrainData,validation_data\u001b[38;5;241m=\u001b[39mTestData,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[LRcallback])\n\u001b[0;32m      2\u001b[0m TrainTracker\u001b[38;5;241m=\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory\n",
      "File \u001b[1;32mc:\\Users\\abhishek\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     arguments_context\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  • \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arguments_context:\n\u001b[1;32m--> 122\u001b[0m     arguments_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(arguments_context)\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# Get original error message and append information to it.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOpError):\n",
      "File \u001b[1;32mc:\\Users\\abhishek\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\progbar.py:119\u001b[0m, in \u001b[0;36mupdate\u001b[1;34m(self, current, values, finalize)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "history=Siamesmodel.fit(TrainData,validation_data=TestData,epochs=40, callbacks=[LRcallback])\n",
    "TrainTracker=history.history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
